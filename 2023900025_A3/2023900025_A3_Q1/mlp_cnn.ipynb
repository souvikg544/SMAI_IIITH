{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b366beb8-cf14-4839-b768-319e020128f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import v2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a4de70-d662-4185-b4dd-d89336576601",
   "metadata": {},
   "source": [
    "**Download CIFAR-10 and CIFAR-100 from the provided links.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d45aa8a-ef94-4391-bfe8-f03870fae3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-28 19:58:13--  https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
      "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 170498071 (163M) [application/x-gzip]\n",
      "Saving to: ‘/ssd_scratch/cvit/sou/cifar-10-python.tar.gz’\n",
      "\n",
      "cifar-10-python.tar 100%[===================>] 162.60M   778KB/s    in 4m 18s  \n",
      "\n",
      "2024-03-28 20:02:33 (646 KB/s) - ‘/ssd_scratch/cvit/sou/cifar-10-python.tar.gz’ saved [170498071/170498071]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget -P /ssd_scratch/cvit/sou/ https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f577f200-6992-4f52-87c3-b0a41a7e34fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-28 20:02:33--  https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
      "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 169001437 (161M) [application/x-gzip]\n",
      "Saving to: ‘/ssd_scratch/cvit/sou/cifar-100-python.tar.gz’\n",
      "\n",
      "cifar-100-python.ta 100%[===================>] 161.17M  7.78MB/s    in 44s     \n",
      "\n",
      "2024-03-28 20:03:18 (3.69 MB/s) - ‘/ssd_scratch/cvit/sou/cifar-100-python.tar.gz’ saved [169001437/169001437]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget -P /ssd_scratch/cvit/sou/ https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4614f103-53a2-45a0-84b6-ce16927d98d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar-10-batches-py/\n",
      "cifar-10-batches-py/data_batch_4\n",
      "cifar-10-batches-py/readme.html\n",
      "cifar-10-batches-py/test_batch\n",
      "cifar-10-batches-py/data_batch_3\n",
      "cifar-10-batches-py/batches.meta\n",
      "cifar-10-batches-py/data_batch_2\n",
      "cifar-10-batches-py/data_batch_5\n",
      "cifar-10-batches-py/data_batch_1\n",
      "cifar-100-python/\n",
      "cifar-100-python/file.txt~\n",
      "cifar-100-python/train\n",
      "cifar-100-python/test\n",
      "cifar-100-python/meta\n"
     ]
    }
   ],
   "source": [
    "! tar -xzvf /ssd_scratch/cvit/sou/cifar-10-python.tar.gz\n",
    "! tar -xzvf /ssd_scratch/cvit/sou/cifar-100-python.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c88b7d-1b10-4663-8b91-b9b854b7daba",
   "metadata": {},
   "source": [
    "**Data Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3997eda-8420-4c64-9b13-1efd7f75db2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f507a89-22f5-4d5b-9cc3-f32e1a4f1ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cf10 = unpickle('/ssd_scratch/cvit/sou/cifar-10-batches-py/data_batch_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be7c75e1-68fd-4085-9acb-df68b707df5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([b'batch_label', b'labels', b'data', b'filenames'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cf10.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f03b8d57-2b7e-4c80-9600-37212e149b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_cf10[b'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b517278-e29e-4a36-b1d4-5b8ad9546881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_cf10[b'data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0394e595-f382-4779-9338-4d9a220982bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3072)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cf10[b'data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4c71542-75ec-42f2-8f4c-17d27b24c634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_cf10[b'filenames'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62c4cc32-ffce-439a-8ad5-ea35f4bad1d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'abandoned_ship_s_000574.png'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cf10[b'filenames'][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fd59441-eba1-4c15-bc61-a13f93cb2dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array = train_cf10[b'data'][100]\n",
    "label = str(train_cf10[b'filenames'][100]).split('_')[0].replace(r\"b'\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "452f28a5-ce6f-4664-aa71-c4a6d127caca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label is -- abandoned\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3,3))\n",
    "image_R = np.reshape(image_array[0:1024], (32,32))\n",
    "image_G = np.reshape(image_array[1024:2048], (32,32))\n",
    "image_B = np.reshape(image_array[2048:4096], (32,32))\n",
    "image = np.dstack((image_R, image_G, image_B))\n",
    "print(\"Label is --\",label)\n",
    "plt.imshow(image)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37e58ccf-fa6c-4fa7-84a9-e71b4b38db8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cf10[b'labels'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490644bd-50e4-459d-992c-9d8d799b07d2",
   "metadata": {},
   "source": [
    "**Building dataloader and traning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "448d4493-bf95-41a7-8142-636295606c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cifar(Dataset):\n",
    "    def __init__(self, root_dir,train=True):\n",
    "        self.root_dir = root_dir\n",
    "        self.cf10 = unpickle(self.root_dir)\n",
    "        if train:\n",
    "            self.transforms = v2.Compose([\n",
    "                v2.RandomHorizontalFlip(p=0.5),\n",
    "                v2.ToDtype(torch.float32, scale=True),\n",
    "                v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "        else :\n",
    "            self.transforms = v2.Compose([\n",
    "                v2.ToDtype(torch.float32, scale=True),\n",
    "                v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(train_cf10[b'labels'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_array = self.cf10[b'data'][idx]\n",
    "        image_R = np.reshape(image_array[0:1024], (32,32))\n",
    "        image_G = np.reshape(image_array[1024:2048], (32,32))\n",
    "        image_B = np.reshape(image_array[2048:4096], (32,32))\n",
    "        image = np.dstack((image_R, image_G, image_B))\n",
    "\n",
    "        label = self.cf10[b'labels'][idx]\n",
    "        \n",
    "        image_tensor = torch.FloatTensor(image)\n",
    "        return image_tensor.permute(2,0,1), torch.tensor(label)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45685463-5dff-45a5-a1de-f1882b6bbcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_train_dataset = cifar(root_dir = '/ssd_scratch/cvit/sou/cifar-10-batches-py/data_batch_1')\n",
    "cifar10_test_dataset = cifar(root_dir = '/ssd_scratch/cvit/sou/cifar-10-batches-py/test_batch', train=False)\n",
    "train_dataloader_cifar10 = DataLoader(cifar10_train_dataset, batch_size=128, shuffle=True)\n",
    "test_dataloader_cifar10 = DataLoader(cifar10_test_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d36ef42c-f09f-4e73-b490-ed9d02405fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader_cifar10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "102f7b4f-83bd-4172-87ec-5133a6055265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10_test_dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4c16141-3b83-476e-8d23-d59ac58b4cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10_train_dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28c7ed50-5f24-4d5e-a235-201fde5d96c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f75da97b-ed1e-4937-ad93-db7c91483f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "def calc_accuracy(pred,true):\n",
    "    output = softmax(pred)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    total = true.size(0)\n",
    "    correct = (predicted == true).sum().item()\n",
    "    return correct/total\n",
    "\n",
    "def evaluate(model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader_cifar10:\n",
    "            images, labels = data\n",
    "            outputs = model(images.cuda())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.cuda()).sum().item()\n",
    "            \n",
    "    print('Accuracy of the MLP network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866c15ac-683a-4fc4-8ff1-399a684a9069",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4372fd3-f085-44c8-becc-33e2c2fe5a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.mlp_modules=nn.ModuleList([\n",
    "        nn.Linear(3 * 32 * 32, 512),\n",
    "        self.relu,\n",
    "        nn.Linear(512, 256),\n",
    "        self.relu,\n",
    "        nn.Linear(256, 128),\n",
    "        self.relu,\n",
    "        nn.Linear(128, 64),\n",
    "        self.relu,\n",
    "        nn.Linear(64, 10)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for f in self.mlp_modules:\n",
    "            x = f(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3dc61c6c-65ae-4f6b-9e96-bc41c77e7382",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a3e62aa-bfb3-4e39-86ba-654e1d4c139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = MLP()\n",
    "mlp_model = mlp_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ead195cf-ec4c-452d-8785-7f0598fe255c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8cd7c17b-600f-458d-ae57-df12f643aba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(mlp_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd12bab4-cf24-48d9-89e0-4f8c7527c7b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1 ----- Step = 78 ----- Loss = 5.27656826791884 ---- Accuracy = 0.14359177215189872\n",
      "Epoch = 2 ----- Step = 78 ----- Loss = 2.0659641857388653 ---- Accuracy = 0.25375791139240506\n",
      "Epoch = 3 ----- Step = 78 ----- Loss = 2.0214084235927725 ---- Accuracy = 0.2775909810126582\n",
      "Epoch = 4 ----- Step = 78 ----- Loss = 1.9154013908362086 ---- Accuracy = 0.317246835443038\n",
      "Epoch = 5 ----- Step = 78 ----- Loss = 1.8579165497912635 ---- Accuracy = 0.3381131329113924\n",
      "Epoch = 6 ----- Step = 78 ----- Loss = 1.8112899940225142 ---- Accuracy = 0.35176028481012656\n",
      "Epoch = 7 ----- Step = 78 ----- Loss = 1.7823176051996932 ---- Accuracy = 0.36204509493670883\n",
      "Epoch = 8 ----- Step = 78 ----- Loss = 1.7512607302846788 ---- Accuracy = 0.3741099683544304\n",
      "Epoch = 9 ----- Step = 78 ----- Loss = 1.7200835807413994 ---- Accuracy = 0.3837025316455696\n",
      "Epoch = 10 ----- Step = 78 ----- Loss = 1.6873287837716597 ---- Accuracy = 0.39804193037974683\n",
      "Epoch = 11 ----- Step = 78 ----- Loss = 1.6739332540125786 ---- Accuracy = 0.40110759493670883\n",
      "Epoch = 12 ----- Step = 78 ----- Loss = 1.6402685702601565 ---- Accuracy = 0.4117879746835443\n",
      "Epoch = 13 ----- Step = 78 ----- Loss = 1.6423406374605396 ---- Accuracy = 0.41475474683544306\n",
      "Epoch = 14 ----- Step = 78 ----- Loss = 1.638656341576878 ---- Accuracy = 0.41663370253164556\n",
      "Epoch = 15 ----- Step = 78 ----- Loss = 1.6123681506024132 ---- Accuracy = 0.43314873417721517\n",
      "Epoch = 16 ----- Step = 78 ----- Loss = 1.5963409807108626 ---- Accuracy = 0.4274129746835443\n",
      "Epoch = 17 ----- Step = 78 ----- Loss = 1.55886433697954 ---- Accuracy = 0.4419501582278481\n",
      "Epoch = 18 ----- Step = 78 ----- Loss = 1.5436814359471769 ---- Accuracy = 0.4465981012658228\n",
      "Epoch = 19 ----- Step = 78 ----- Loss = 1.4943076794660544 ---- Accuracy = 0.4642998417721519\n",
      "Epoch = 20 ----- Step = 78 ----- Loss = 1.5413051013705097 ---- Accuracy = 0.44966376582278483\n",
      "Epoch = 21 ----- Step = 78 ----- Loss = 1.4806100341338146 ---- Accuracy = 0.4743868670886076\n",
      "Epoch = 22 ----- Step = 78 ----- Loss = 1.4837151599835745 ---- Accuracy = 0.4698378164556962\n",
      "Epoch = 23 ----- Step = 78 ----- Loss = 1.4644526439377024 ---- Accuracy = 0.47151898734177217\n",
      "Epoch = 24 ----- Step = 78 ----- Loss = 1.4608398208135291 ---- Accuracy = 0.47399129746835444\n",
      "Epoch = 25 ----- Step = 78 ----- Loss = 1.4313856574553478 ---- Accuracy = 0.48783623417721517\n",
      "Epoch = 26 ----- Step = 78 ----- Loss = 1.40392349037943 ---- Accuracy = 0.5008900316455697\n",
      "Epoch = 27 ----- Step = 78 ----- Loss = 1.4242008683047718 ---- Accuracy = 0.496934335443038\n",
      "Epoch = 28 ----- Step = 78 ----- Loss = 1.4120579475088963 ---- Accuracy = 0.48941851265822783\n",
      "Epoch = 29 ----- Step = 78 ----- Loss = 1.370211608802216 ---- Accuracy = 0.5060324367088608\n",
      "Epoch = 30 ----- Step = 78 ----- Loss = 1.372233276125751 ---- Accuracy = 0.5104825949367089\n",
      "Epoch = 31 ----- Step = 78 ----- Loss = 1.38781967645959 ---- Accuracy = 0.501681170886076\n",
      "Epoch = 32 ----- Step = 78 ----- Loss = 1.3123412403879287 ---- Accuracy = 0.5325356012658228\n",
      "Epoch = 33 ----- Step = 78 ----- Loss = 1.3077925639816477 ---- Accuracy = 0.5300632911392406\n",
      "Epoch = 34 ----- Step = 78 ----- Loss = 1.272202085845078 ---- Accuracy = 0.539754746835443\n",
      "Epoch = 35 ----- Step = 78 ----- Loss = 1.3092927676212938 ---- Accuracy = 0.5236352848101266\n",
      "Epoch = 36 ----- Step = 78 ----- Loss = 1.263430343398565 ---- Accuracy = 0.5454905063291139\n",
      "Epoch = 37 ----- Step = 78 ----- Loss = 1.2589842035800596 ---- Accuracy = 0.5432159810126582\n",
      "Epoch = 38 ----- Step = 78 ----- Loss = 1.2489965988110892 ---- Accuracy = 0.553995253164557\n",
      "Epoch = 39 ----- Step = 78 ----- Loss = 1.2681473252139515 ---- Accuracy = 0.5422270569620253\n",
      "Epoch = 40 ----- Step = 78 ----- Loss = 1.2592854167841658 ---- Accuracy = 0.5513251582278481\n",
      "Epoch = 41 ----- Step = 78 ----- Loss = 1.222318427472175 ---- Accuracy = 0.564181170886076\n",
      "Epoch = 42 ----- Step = 78 ----- Loss = 1.194980808451206 ---- Accuracy = 0.5736748417721519\n",
      "Epoch = 43 ----- Step = 78 ----- Loss = 1.244434174857562 ---- Accuracy = 0.5543908227848101\n",
      "Epoch = 44 ----- Step = 78 ----- Loss = 1.1895852451083027 ---- Accuracy = 0.5671479430379747\n",
      "Epoch = 45 ----- Step = 78 ----- Loss = 1.122202459769913 ---- Accuracy = 0.5929588607594937\n",
      "Epoch = 46 ----- Step = 78 ----- Loss = 1.173315648036667 ---- Accuracy = 0.580498417721519\n",
      "Epoch = 47 ----- Step = 78 ----- Loss = 1.1455440664593177 ---- Accuracy = 0.5953322784810127\n",
      "Epoch = 48 ----- Step = 78 ----- Loss = 1.1436958924124512 ---- Accuracy = 0.5942444620253164\n",
      "Epoch = 49 ----- Step = 78 ----- Loss = 1.0938039399400543 ---- Accuracy = 0.6043314873417721\n",
      "Epoch = 50 ----- Step = 78 ----- Loss = 1.0846626690671415 ---- Accuracy = 0.612440664556962\n",
      "Epoch = 51 ----- Step = 78 ----- Loss = 1.0334533588795722 ---- Accuracy = 0.6291534810126582\n",
      "Epoch = 52 ----- Step = 78 ----- Loss = 1.0973206079458888 ---- Accuracy = 0.6083860759493671\n",
      "Epoch = 53 ----- Step = 78 ----- Loss = 1.0367125966880895 ---- Accuracy = 0.6255933544303798\n",
      "Epoch = 54 ----- Step = 78 ----- Loss = 1.03469001039674 ---- Accuracy = 0.6239121835443038\n",
      "Epoch = 55 ----- Step = 78 ----- Loss = 1.0405740896357765 ---- Accuracy = 0.6268789556962026\n",
      "Epoch = 56 ----- Step = 78 ----- Loss = 1.041197510459755 ---- Accuracy = 0.6295490506329114\n",
      "Epoch = 57 ----- Step = 78 ----- Loss = 1.0038924224769012 ---- Accuracy = 0.6416139240506329\n",
      "Epoch = 58 ----- Step = 78 ----- Loss = 0.9347960752776906 ---- Accuracy = 0.6604034810126582\n",
      "Epoch = 59 ----- Step = 78 ----- Loss = 0.921983497052253 ---- Accuracy = 0.6663370253164557\n",
      "Epoch = 60 ----- Step = 78 ----- Loss = 0.9029798545414889 ---- Accuracy = 0.6734572784810127\n",
      "Epoch = 61 ----- Step = 78 ----- Loss = 0.954041565520854 ---- Accuracy = 0.6536787974683544\n",
      "Epoch = 62 ----- Step = 78 ----- Loss = 0.9157507110245621 ---- Accuracy = 0.6699960443037974\n",
      "Epoch = 63 ----- Step = 78 ----- Loss = 0.8964857376074489 ---- Accuracy = 0.6782041139240507\n",
      "Epoch = 64 ----- Step = 78 ----- Loss = 0.9164583313314221 ---- Accuracy = 0.6686115506329114\n",
      "Epoch = 65 ----- Step = 78 ----- Loss = 0.927943848356416 ---- Accuracy = 0.6669303797468354\n",
      "Epoch = 66 ----- Step = 78 ----- Loss = 0.884553884403615 ---- Accuracy = 0.6808742088607594\n",
      "Epoch = 67 ----- Step = 78 ----- Loss = 0.8899164765695983 ---- Accuracy = 0.6799841772151899\n",
      "Epoch = 68 ----- Step = 78 ----- Loss = 0.8420376189147369 ---- Accuracy = 0.6970925632911392\n",
      "Epoch = 69 ----- Step = 78 ----- Loss = 0.8110657311693023 ---- Accuracy = 0.7029272151898734\n",
      "Epoch = 70 ----- Step = 78 ----- Loss = 0.8636010409910467 ---- Accuracy = 0.6883900316455697\n",
      "Epoch = 71 ----- Step = 78 ----- Loss = 0.9112103000471864 ---- Accuracy = 0.6762262658227848\n",
      "Epoch = 72 ----- Step = 78 ----- Loss = 0.8251298560371881 ---- Accuracy = 0.6988726265822784\n",
      "Epoch = 73 ----- Step = 78 ----- Loss = 0.8306304005127919 ---- Accuracy = 0.6992681962025317\n",
      "Epoch = 74 ----- Step = 78 ----- Loss = 0.7237697719018671 ---- Accuracy = 0.7409018987341772\n",
      "Epoch = 75 ----- Step = 78 ----- Loss = 0.7942947918855692 ---- Accuracy = 0.7159810126582279\n",
      "Epoch = 76 ----- Step = 78 ----- Loss = 0.7578620148610465 ---- Accuracy = 0.7268591772151899\n",
      "Epoch = 77 ----- Step = 78 ----- Loss = 0.7068433897404731 ---- Accuracy = 0.7491099683544303\n",
      "Epoch = 78 ----- Step = 78 ----- Loss = 0.8155251499972765 ---- Accuracy = 0.703817246835443\n",
      "Epoch = 79 ----- Step = 78 ----- Loss = 0.6663258894334866 ---- Accuracy = 0.7559335443037974\n",
      "Epoch = 80 ----- Step = 78 ----- Loss = 0.731493964225431 ---- Accuracy = 0.7415941455696202\n",
      "Epoch = 81 ----- Step = 78 ----- Loss = 0.670387416323529 ---- Accuracy = 0.7577136075949367\n",
      "Epoch = 82 ----- Step = 78 ----- Loss = 0.6823598055899898 ---- Accuracy = 0.7515822784810127\n",
      "Epoch = 83 ----- Step = 78 ----- Loss = 0.6659615092639681 ---- Accuracy = 0.7598892405063291\n",
      "Epoch = 84 ----- Step = 78 ----- Loss = 0.6989174583290196 ---- Accuracy = 0.7502966772151899\n",
      "Epoch = 85 ----- Step = 78 ----- Loss = 0.6833551503434966 ---- Accuracy = 0.7560324367088608\n",
      "Epoch = 86 ----- Step = 78 ----- Loss = 0.650805987512009 ---- Accuracy = 0.7693829113924051\n",
      "Epoch = 87 ----- Step = 78 ----- Loss = 0.6560070095937464 ---- Accuracy = 0.762559335443038\n",
      "Epoch = 88 ----- Step = 78 ----- Loss = 0.6625088159042068 ---- Accuracy = 0.7589992088607594\n",
      "Epoch = 89 ----- Step = 78 ----- Loss = 0.6301278928412667 ---- Accuracy = 0.7726463607594937\n",
      "Epoch = 90 ----- Step = 78 ----- Loss = 0.5830899824070025 ---- Accuracy = 0.7903481012658228\n",
      "Epoch = 91 ----- Step = 78 ----- Loss = 0.6356977726085277 ---- Accuracy = 0.7729430379746836\n",
      "Epoch = 92 ----- Step = 78 ----- Loss = 0.6244948087613794 ---- Accuracy = 0.7767009493670886\n",
      "Epoch = 93 ----- Step = 78 ----- Loss = 0.7030217232583444 ---- Accuracy = 0.7520767405063291\n",
      "Epoch = 94 ----- Step = 78 ----- Loss = 0.570297833862184 ---- Accuracy = 0.796182753164557\n",
      "Epoch = 95 ----- Step = 78 ----- Loss = 0.5650813243811643 ---- Accuracy = 0.7978639240506329\n",
      "Epoch = 96 ----- Step = 78 ----- Loss = 0.6681649003979526 ---- Accuracy = 0.763943829113924\n",
      "Epoch = 97 ----- Step = 78 ----- Loss = 0.5266182392458373 ---- Accuracy = 0.8144778481012658\n",
      "Epoch = 98 ----- Step = 78 ----- Loss = 0.5316451188129715 ---- Accuracy = 0.8083465189873418\n",
      "Epoch = 99 ----- Step = 78 ----- Loss = 0.6195990190475802 ---- Accuracy = 0.7828322784810127\n",
      "Epoch = 100 ----- Step = 78 ----- Loss = 0.5273793852781947 ---- Accuracy = 0.810818829113924\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Train the MLP model\n",
    "epochs = 100\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    running_total = 0\n",
    "    for i, data in enumerate(train_dataloader_cifar10, 0):\n",
    "        total_len = len(train_dataloader_cifar10) -1\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = mlp_model(inputs.reshape(inputs.size(0),-1).cuda())\n",
    "        loss = criterion(logits, labels.cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_total +=1\n",
    "        accuracy+=calc_accuracy(logits,labels.cuda())\n",
    "        #if i % 10 == 0 or i == total_len :  # print every 2000 mini-batches\n",
    "        if i == total_len :\n",
    "            print(f\"Epoch = {epoch+1} ----- Step = {i} ----- Loss = {running_loss/running_total} ---- Accuracy = {accuracy/running_total}\")\n",
    "            running_loss = 0.0\n",
    "            accuracy = 0.0\n",
    "            running_total = 0\n",
    "\n",
    "print('Finished Training')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a1ab8a1-f3f0-45a0-8154-56e7692e7582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the MLP network on the 10000 test images: 42 %\n"
     ]
    }
   ],
   "source": [
    "# Evaluating MLP model on test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader_cifar10:\n",
    "        images, labels = data\n",
    "        outputs = mlp_model(images.reshape(images.size(0),-1).cuda())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.cuda()).sum().item()\n",
    "        \n",
    "print('Accuracy of the MLP network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d96abaa-08b3-4d84-b929-896ba155a203",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a5bc9c46-a7d0-4d80-b474-09260fe4e704",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2dBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, residual=False, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.conv_block = nn.Sequential(\n",
    "                            nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding),\n",
    "                             nn.BatchNorm2d(out_channels)\n",
    "                        )\n",
    "        for layer in self.conv_block:\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(layer.weight)\n",
    "        self.act = nn.ReLU()\n",
    "        self.residual = residual\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv_block(x)\n",
    "        if self.residual:\n",
    "            out += x\n",
    "        return self.act(out)\n",
    "\n",
    "\n",
    "class cnn_arch(nn.Module):\n",
    "    def __init__(self, in_channel = 3, num_classes = 10):\n",
    "        super(cnn_arch, self).__init__()\n",
    "\n",
    "        \n",
    "\n",
    "        self.mini_resnet=nn.ModuleList([ \n",
    "            #32\n",
    "            nn.Sequential(\n",
    "                Conv2dBlock(in_channels=in_channel, out_channels=32, kernel_size=(5,5), stride=(2,2), padding=2),\n",
    "                Conv2dBlock(in_channels=32, out_channels=32, kernel_size=(5,5), stride=1, padding=2,residual=True),\n",
    "                nn.Dropout(0.20)\n",
    "            ),\n",
    "            #16\n",
    "            nn.Sequential(\n",
    "                Conv2dBlock(in_channels=32, out_channels=64, kernel_size=(5,5), stride=(2,2), padding=2),\n",
    "                Conv2dBlock(in_channels=64, out_channels=64, kernel_size=(5,5), stride=1, padding=2,residual=True),\n",
    "                nn.Dropout(0.20)\n",
    "            ),\n",
    "            \n",
    "            #8\n",
    "            nn.Sequential(\n",
    "                Conv2dBlock(in_channels=64, out_channels=128, kernel_size=(5,5), stride=(2,2), padding=2),\n",
    "                Conv2dBlock(in_channels=128, out_channels=128, kernel_size=(5,5), stride=1, padding=2,residual=True),\n",
    "                nn.Dropout(0.20)\n",
    "            )])\n",
    "            \n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.fc1 = nn.Linear(128*4*4, 128)\n",
    "        self.fc2 = nn.Linear(128,num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.size()\n",
    "        for f in self.mini_resnet:\n",
    "            x = f(x)\n",
    "        x = x.view(x.size()[0],-1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9264ad2d-558c-4507-8413-b06acdc60760",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = cnn_arch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "213ec3aa-6ea5-48e7-a60a-49e39a511bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cnn(torch.rand((16,3,32,32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "59f6dea3-7e92-4d08-b1a8-4456dee37b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 10])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5222cd38-0672-4209-a13e-11d9be35a3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = cnn.to(device)\n",
    "optimizer = optim.Adam(cnn.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "789fcd18-0e19-4ecb-b3f1-6d64ec381887",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1 ----- Step = 78 ----- Loss = 0.11288394529042364 ---- Accuracy = 0.961629746835443\n",
      "Epoch = 2 ----- Step = 78 ----- Loss = 0.10799379151644586 ---- Accuracy = 0.9643987341772152\n",
      "Epoch = 3 ----- Step = 78 ----- Loss = 0.09804563804329196 ---- Accuracy = 0.9658821202531646\n",
      "Epoch = 4 ----- Step = 78 ----- Loss = 0.10608645832708365 ---- Accuracy = 0.9637064873417721\n",
      "Epoch = 5 ----- Step = 78 ----- Loss = 0.07784696798064286 ---- Accuracy = 0.9737935126582279\n",
      "Epoch = 6 ----- Step = 78 ----- Loss = 0.07672947230218333 ---- Accuracy = 0.9724090189873418\n",
      "Epoch = 7 ----- Step = 78 ----- Loss = 0.06798825059321863 ---- Accuracy = 0.9769580696202531\n",
      "Epoch = 8 ----- Step = 78 ----- Loss = 0.06379839511370121 ---- Accuracy = 0.9790348101265823\n",
      "Epoch = 9 ----- Step = 78 ----- Loss = 0.06570701345895665 ---- Accuracy = 0.9779469936708861\n",
      "Epoch = 10 ----- Step = 78 ----- Loss = 0.09688134515021421 ---- Accuracy = 0.9673655063291139\n",
      "Epoch = 11 ----- Step = 78 ----- Loss = 0.08034494229226927 ---- Accuracy = 0.9723101265822784\n",
      "Epoch = 12 ----- Step = 78 ----- Loss = 0.07505661285706336 ---- Accuracy = 0.9769580696202531\n",
      "Epoch = 13 ----- Step = 78 ----- Loss = 0.10586566133778307 ---- Accuracy = 0.9623219936708861\n",
      "Epoch = 14 ----- Step = 78 ----- Loss = 0.08594848433969236 ---- Accuracy = 0.9681566455696202\n",
      "Epoch = 15 ----- Step = 78 ----- Loss = 0.062114186349171624 ---- Accuracy = 0.9776503164556962\n",
      "Epoch = 16 ----- Step = 78 ----- Loss = 0.08594505894410459 ---- Accuracy = 0.9693433544303798\n",
      "Epoch = 17 ----- Step = 78 ----- Loss = 0.06098723662663487 ---- Accuracy = 0.9793314873417721\n",
      "Epoch = 18 ----- Step = 78 ----- Loss = 0.05570286407453727 ---- Accuracy = 0.9800237341772152\n",
      "Epoch = 19 ----- Step = 78 ----- Loss = 0.05338497213500587 ---- Accuracy = 0.9815071202531646\n",
      "Epoch = 20 ----- Step = 78 ----- Loss = 0.1101665883030318 ---- Accuracy = 0.9627175632911392\n",
      "Epoch = 21 ----- Step = 78 ----- Loss = 0.05781013426618486 ---- Accuracy = 0.9793314873417721\n",
      "Epoch = 22 ----- Step = 78 ----- Loss = 0.06523873985898268 ---- Accuracy = 0.9773536392405063\n",
      "Epoch = 23 ----- Step = 78 ----- Loss = 0.056070853449121306 ---- Accuracy = 0.9790348101265823\n",
      "Epoch = 24 ----- Step = 78 ----- Loss = 0.0919440925722541 ---- Accuracy = 0.9688488924050633\n",
      "Epoch = 25 ----- Step = 78 ----- Loss = 0.0533648916885634 ---- Accuracy = 0.9803204113924051\n",
      "Epoch = 26 ----- Step = 78 ----- Loss = 0.04208261029252523 ---- Accuracy = 0.9852650316455697\n",
      "Epoch = 27 ----- Step = 78 ----- Loss = 0.0497615806510837 ---- Accuracy = 0.983682753164557\n",
      "Epoch = 28 ----- Step = 78 ----- Loss = 0.050286496282095396 ---- Accuracy = 0.9831882911392406\n",
      "Epoch = 29 ----- Step = 78 ----- Loss = 0.05391860282331516 ---- Accuracy = 0.982693829113924\n",
      "Epoch = 30 ----- Step = 78 ----- Loss = 0.05158754160533412 ---- Accuracy = 0.9823971518987342\n",
      "Epoch = 31 ----- Step = 78 ----- Loss = 0.03957253827748797 ---- Accuracy = 0.9864517405063291\n",
      "Epoch = 32 ----- Step = 78 ----- Loss = 0.050047198499116714 ---- Accuracy = 0.9821004746835443\n",
      "Epoch = 33 ----- Step = 78 ----- Loss = 0.04998770090928183 ---- Accuracy = 0.9830893987341772\n",
      "Epoch = 34 ----- Step = 78 ----- Loss = 0.04032146798658975 ---- Accuracy = 0.986056170886076\n",
      "Epoch = 35 ----- Step = 78 ----- Loss = 0.057973330557534966 ---- Accuracy = 0.9810126582278481\n",
      "Epoch = 36 ----- Step = 78 ----- Loss = 0.03885085347898399 ---- Accuracy = 0.9863528481012658\n",
      "Epoch = 37 ----- Step = 78 ----- Loss = 0.03543401188276048 ---- Accuracy = 0.9877373417721519\n",
      "Epoch = 38 ----- Step = 78 ----- Loss = 0.043077872187795144 ---- Accuracy = 0.986748417721519\n",
      "Epoch = 39 ----- Step = 78 ----- Loss = 0.03823252025213611 ---- Accuracy = 0.9871439873417721\n",
      "Epoch = 40 ----- Step = 78 ----- Loss = 0.040852934732160805 ---- Accuracy = 0.9849683544303798\n",
      "Epoch = 41 ----- Step = 78 ----- Loss = 0.030749318823572014 ---- Accuracy = 0.9890229430379747\n",
      "Epoch = 42 ----- Step = 78 ----- Loss = 0.038234638512912617 ---- Accuracy = 0.986056170886076\n",
      "Epoch = 43 ----- Step = 78 ----- Loss = 0.04555442123497023 ---- Accuracy = 0.9858583860759493\n",
      "Epoch = 44 ----- Step = 78 ----- Loss = 0.03666215003291263 ---- Accuracy = 0.987440664556962\n",
      "Epoch = 45 ----- Step = 78 ----- Loss = 0.031972160356567254 ---- Accuracy = 0.9895174050632911\n",
      "Epoch = 46 ----- Step = 78 ----- Loss = 0.047996772140783225 ---- Accuracy = 0.9841772151898734\n",
      "Epoch = 47 ----- Step = 78 ----- Loss = 0.05355163679540723 ---- Accuracy = 0.982001582278481\n",
      "Epoch = 48 ----- Step = 78 ----- Loss = 0.039944531118992384 ---- Accuracy = 0.987440664556962\n",
      "Epoch = 49 ----- Step = 78 ----- Loss = 0.05912208611357816 ---- Accuracy = 0.9812104430379747\n",
      "Epoch = 50 ----- Step = 78 ----- Loss = 0.038899214885232944 ---- Accuracy = 0.9872428797468354\n",
      "Epoch = 51 ----- Step = 78 ----- Loss = 0.039321431677929966 ---- Accuracy = 0.9856606012658228\n",
      "Epoch = 52 ----- Step = 78 ----- Loss = 0.0364508624188602 ---- Accuracy = 0.9883306962025317\n",
      "Epoch = 53 ----- Step = 78 ----- Loss = 0.033361678218021044 ---- Accuracy = 0.9892207278481012\n",
      "Epoch = 54 ----- Step = 78 ----- Loss = 0.03698775881630239 ---- Accuracy = 0.9881329113924051\n",
      "Epoch = 55 ----- Step = 78 ----- Loss = 0.033667959745706626 ---- Accuracy = 0.9887262658227848\n",
      "Epoch = 56 ----- Step = 78 ----- Loss = 0.027376247216251832 ---- Accuracy = 0.9908030063291139\n",
      "Epoch = 57 ----- Step = 78 ----- Loss = 0.03230525388181964 ---- Accuracy = 0.9889240506329114\n",
      "Epoch = 58 ----- Step = 78 ----- Loss = 0.052160827263223034 ---- Accuracy = 0.9851661392405063\n",
      "Epoch = 59 ----- Step = 78 ----- Loss = 0.055658763645900576 ---- Accuracy = 0.9823971518987342\n",
      "Epoch = 60 ----- Step = 78 ----- Loss = 0.04554415541359141 ---- Accuracy = 0.9847705696202531\n",
      "Epoch = 61 ----- Step = 78 ----- Loss = 0.032142971164865204 ---- Accuracy = 0.9881329113924051\n",
      "Epoch = 62 ----- Step = 78 ----- Loss = 0.02781276649035089 ---- Accuracy = 0.989814082278481\n",
      "Epoch = 63 ----- Step = 78 ----- Loss = 0.03539230355026224 ---- Accuracy = 0.9881329113924051\n",
      "Epoch = 64 ----- Step = 78 ----- Loss = 0.03007512404642339 ---- Accuracy = 0.9910007911392406\n",
      "Epoch = 65 ----- Step = 78 ----- Loss = 0.061303486440425055 ---- Accuracy = 0.9804193037974683\n",
      "Epoch = 66 ----- Step = 78 ----- Loss = 0.04241582600965719 ---- Accuracy = 0.9854628164556962\n",
      "Epoch = 67 ----- Step = 78 ----- Loss = 0.027314583573466802 ---- Accuracy = 0.9909018987341772\n",
      "Epoch = 68 ----- Step = 78 ----- Loss = 0.04021798557000635 ---- Accuracy = 0.9869462025316456\n",
      "Epoch = 69 ----- Step = 78 ----- Loss = 0.036416664236236976 ---- Accuracy = 0.9863528481012658\n",
      "Epoch = 70 ----- Step = 78 ----- Loss = 0.060322662356329486 ---- Accuracy = 0.9801226265822784\n",
      "Epoch = 71 ----- Step = 78 ----- Loss = 0.03019366256562592 ---- Accuracy = 0.9902096518987342\n",
      "Epoch = 72 ----- Step = 78 ----- Loss = 0.044563193619840694 ---- Accuracy = 0.9841772151898734\n",
      "Epoch = 73 ----- Step = 78 ----- Loss = 0.026847318592893927 ---- Accuracy = 0.9906052215189873\n",
      "Epoch = 74 ----- Step = 78 ----- Loss = 0.021549061561133006 ---- Accuracy = 0.9929786392405063\n",
      "Epoch = 75 ----- Step = 78 ----- Loss = 0.02073650804784479 ---- Accuracy = 0.9922863924050633\n",
      "Epoch = 76 ----- Step = 78 ----- Loss = 0.021783971693366766 ---- Accuracy = 0.9933742088607594\n",
      "Epoch = 77 ----- Step = 78 ----- Loss = 0.022910988992787425 ---- Accuracy = 0.9925830696202531\n",
      "Epoch = 78 ----- Step = 78 ----- Loss = 0.04122611781128364 ---- Accuracy = 0.986748417721519\n",
      "Epoch = 79 ----- Step = 78 ----- Loss = 0.03859038352141086 ---- Accuracy = 0.9868473101265823\n",
      "Epoch = 80 ----- Step = 78 ----- Loss = 0.024397414805414745 ---- Accuracy = 0.990506329113924\n",
      "Epoch = 81 ----- Step = 78 ----- Loss = 0.02128431485240831 ---- Accuracy = 0.9926819620253164\n",
      "Epoch = 82 ----- Step = 78 ----- Loss = 0.026088155661650663 ---- Accuracy = 0.9918908227848101\n",
      "Epoch = 83 ----- Step = 78 ----- Loss = 0.02507001990481881 ---- Accuracy = 0.9916930379746836\n",
      "Epoch = 84 ----- Step = 78 ----- Loss = 0.03454088086750111 ---- Accuracy = 0.9895174050632911\n",
      "Epoch = 85 ----- Step = 78 ----- Loss = 0.026951625833031425 ---- Accuracy = 0.9907041139240507\n",
      "Epoch = 86 ----- Step = 78 ----- Loss = 0.01912559726705798 ---- Accuracy = 0.9933742088607594\n",
      "Epoch = 87 ----- Step = 78 ----- Loss = 0.01664443236784538 ---- Accuracy = 0.9943631329113924\n",
      "Epoch = 88 ----- Step = 78 ----- Loss = 0.023494831307185517 ---- Accuracy = 0.9919897151898734\n",
      "Epoch = 89 ----- Step = 78 ----- Loss = 0.025102890348592418 ---- Accuracy = 0.9913963607594937\n",
      "Epoch = 90 ----- Step = 78 ----- Loss = 0.026968737446726596 ---- Accuracy = 0.9907041139240507\n",
      "Epoch = 91 ----- Step = 78 ----- Loss = 0.026953488964104107 ---- Accuracy = 0.990506329113924\n",
      "Epoch = 92 ----- Step = 78 ----- Loss = 0.024811540385104032 ---- Accuracy = 0.991495253164557\n",
      "Epoch = 93 ----- Step = 78 ----- Loss = 0.026186968969134024 ---- Accuracy = 0.9913963607594937\n",
      "Epoch = 94 ----- Step = 78 ----- Loss = 0.016389346416285144 ---- Accuracy = 0.9946598101265823\n",
      "Epoch = 95 ----- Step = 78 ----- Loss = 0.031119477936608977 ---- Accuracy = 0.9895174050632911\n",
      "Epoch = 96 ----- Step = 78 ----- Loss = 0.05556268540588267 ---- Accuracy = 0.981309335443038\n",
      "Epoch = 97 ----- Step = 78 ----- Loss = 0.02622139774103755 ---- Accuracy = 0.9910007911392406\n",
      "Epoch = 98 ----- Step = 78 ----- Loss = 0.02538654542398415 ---- Accuracy = 0.9924841772151899\n",
      "Epoch = 99 ----- Step = 78 ----- Loss = 0.025799374502812382 ---- Accuracy = 0.9910996835443038\n",
      "Epoch = 100 ----- Step = 78 ----- Loss = 0.026073431573318952 ---- Accuracy = 0.9910007911392406\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Train the CNN model\n",
    "epochs = 100\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    running_total = 0\n",
    "    for i, data in enumerate(train_dataloader_cifar10, 0):\n",
    "        total_len = len(train_dataloader_cifar10) -1\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = cnn(inputs.cuda())\n",
    "        loss = criterion(logits, labels.cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_total +=1\n",
    "        accuracy+=calc_accuracy(logits,labels.cuda())\n",
    "        #if i % 10 == 0 or i == total_len :  # print every 2000 mini-batches\n",
    "        if i == total_len :\n",
    "            print(f\"Epoch = {epoch+1} ----- Step = {i} ----- Loss = {running_loss/running_total} ---- Accuracy = {accuracy/running_total}\")\n",
    "            running_loss = 0.0\n",
    "            accuracy = 0.0\n",
    "            running_total = 0\n",
    "\n",
    "print('Finished Training')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cbeab00f-bcbb-4601-b5be-c75912c35d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the MLP network on the 10000 test images: 59 %\n"
     ]
    }
   ],
   "source": [
    "evaluate(cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4c9217-fb8a-43db-8174-5ece0b2d7ae7",
   "metadata": {},
   "source": [
    "We see how MLPs achieve an accuracy of 80% on the training set whereas CNNs can go up till 99%.Although it appears that our basic CNN architecture overfits on this data still we get a test accuracy of 59% which is a major increase from the test accuracy of MLPs. This shows how well CNNs capture the both global and local features in an image. It is to be noted that both our test and train sets contain 10k images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03060baa-3bc1-4679-bd6a-45752b6bd7c7",
   "metadata": {},
   "source": [
    "## VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "02d84dad-b466-48d5-9484-09a59c55e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "vgg_model = models.vgg16(weights='DEFAULT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b1ee2c0a-5482-4e4a-9afa-5aa72920dd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze convolutional layers\n",
    "for name,param in vgg_model.named_parameters():\n",
    "    #print(name,param.shape)\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "de2a9394-d63b-4545-9d52-760135c9e45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in vgg_model.classifier[-8:].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in vgg_model.features[:4].parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "be3bf85a-6ced-4ecb-819f-7711bfe6356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are changing the last linear layer of our VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7864ea8f-2dcc-4a84-a291-427267253db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.classifier[6] = nn.Linear(4096, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fa0a25e2-0272-4ea7-bea2-b628033a1801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.weight torch.Size([64, 3, 3, 3]) True\n",
      "features.0.bias torch.Size([64]) True\n",
      "features.2.weight torch.Size([64, 64, 3, 3]) True\n",
      "features.2.bias torch.Size([64]) True\n",
      "features.5.weight torch.Size([128, 64, 3, 3]) False\n",
      "features.5.bias torch.Size([128]) False\n",
      "features.7.weight torch.Size([128, 128, 3, 3]) False\n",
      "features.7.bias torch.Size([128]) False\n",
      "features.10.weight torch.Size([256, 128, 3, 3]) False\n",
      "features.10.bias torch.Size([256]) False\n",
      "features.12.weight torch.Size([256, 256, 3, 3]) False\n",
      "features.12.bias torch.Size([256]) False\n",
      "features.14.weight torch.Size([256, 256, 3, 3]) False\n",
      "features.14.bias torch.Size([256]) False\n",
      "features.17.weight torch.Size([512, 256, 3, 3]) False\n",
      "features.17.bias torch.Size([512]) False\n",
      "features.19.weight torch.Size([512, 512, 3, 3]) False\n",
      "features.19.bias torch.Size([512]) False\n",
      "features.21.weight torch.Size([512, 512, 3, 3]) False\n",
      "features.21.bias torch.Size([512]) False\n",
      "features.24.weight torch.Size([512, 512, 3, 3]) False\n",
      "features.24.bias torch.Size([512]) False\n",
      "features.26.weight torch.Size([512, 512, 3, 3]) False\n",
      "features.26.bias torch.Size([512]) False\n",
      "features.28.weight torch.Size([512, 512, 3, 3]) False\n",
      "features.28.bias torch.Size([512]) False\n",
      "classifier.0.weight torch.Size([4096, 25088]) True\n",
      "classifier.0.bias torch.Size([4096]) True\n",
      "classifier.3.weight torch.Size([4096, 4096]) True\n",
      "classifier.3.bias torch.Size([4096]) True\n",
      "classifier.6.weight torch.Size([10, 4096]) True\n",
      "classifier.6.bias torch.Size([10]) True\n"
     ]
    }
   ],
   "source": [
    "for name,param in vgg_model.named_parameters():\n",
    "    print(name,param.shape,param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0059bfa8-5705-4080-b6c8-6d6994d159a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = vgg_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bcbc2dfd-f9aa-463c-97c9-e8bd37fd5512",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_vgg = optim.Adam(vgg_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "396d5f90-5274-42a6-9092-02c7daa96357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for param in vgg_model.parameters():\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4bb21f45-bc8e-4966-88e6-bb8c36b8fe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def examine_grad(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.grad is not None:\n",
    "            print(f'{name}: Gradient shape - {param.grad.shape}  --- Requires grad {param.requires_grad}')\n",
    "        else:\n",
    "            print(f'{name}: Gradient shape - {param.grad}  --- Requires grad {param.requires_grad}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2ca05858-33f6-4b31-89a3-58f425561761",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1 ----- Step = 78 ----- Loss = 1.4078080156181432 ---- Accuracy = 0.4730023734177215\n",
      "Epoch = 2 ----- Step = 78 ----- Loss = 1.3868608172935775 ---- Accuracy = 0.4814082278481013\n",
      "Epoch = 3 ----- Step = 78 ----- Loss = 1.403942904894865 ---- Accuracy = 0.47695806962025317\n",
      "Epoch = 4 ----- Step = 78 ----- Loss = 1.477664749833602 ---- Accuracy = 0.4566851265822785\n",
      "Epoch = 5 ----- Step = 78 ----- Loss = 1.4386595502684387 ---- Accuracy = 0.46706882911392406\n",
      "Epoch = 6 ----- Step = 78 ----- Loss = 1.4412342370310915 ---- Accuracy = 0.45698180379746833\n",
      "Epoch = 7 ----- Step = 78 ----- Loss = 1.3891775819319714 ---- Accuracy = 0.47794699367088606\n",
      "Epoch = 8 ----- Step = 78 ----- Loss = 1.3600658857369725 ---- Accuracy = 0.489814082278481\n",
      "Epoch = 9 ----- Step = 78 ----- Loss = 1.3809407225138024 ---- Accuracy = 0.48239715189873417\n",
      "Epoch = 10 ----- Step = 78 ----- Loss = 1.381224304814882 ---- Accuracy = 0.4811115506329114\n",
      "Epoch = 11 ----- Step = 78 ----- Loss = 1.3492151076280618 ---- Accuracy = 0.4892207278481013\n",
      "Epoch = 12 ----- Step = 78 ----- Loss = 1.371555455123322 ---- Accuracy = 0.4909018987341772\n",
      "Epoch = 13 ----- Step = 78 ----- Loss = 1.383396050598048 ---- Accuracy = 0.4958465189873418\n",
      "Epoch = 14 ----- Step = 78 ----- Loss = 1.3605942092364347 ---- Accuracy = 0.49406645569620256\n",
      "Epoch = 15 ----- Step = 78 ----- Loss = 1.357147670999358 ---- Accuracy = 0.49713212025316456\n",
      "Epoch = 16 ----- Step = 78 ----- Loss = 1.3930476737927786 ---- Accuracy = 0.49169303797468356\n",
      "Epoch = 17 ----- Step = 78 ----- Loss = 1.3518245039106924 ---- Accuracy = 0.49406645569620256\n",
      "Epoch = 18 ----- Step = 78 ----- Loss = 1.3608591752716257 ---- Accuracy = 0.4991099683544304\n",
      "Epoch = 19 ----- Step = 78 ----- Loss = 1.3483431595790236 ---- Accuracy = 0.5004944620253164\n",
      "Epoch = 20 ----- Step = 78 ----- Loss = 1.3589731666106213 ---- Accuracy = 0.501681170886076\n",
      "Epoch = 21 ----- Step = 78 ----- Loss = 1.339096512975572 ---- Accuracy = 0.5056368670886076\n",
      "Epoch = 22 ----- Step = 78 ----- Loss = 1.3379545045804373 ---- Accuracy = 0.5127571202531646\n",
      "Epoch = 23 ----- Step = 78 ----- Loss = 1.3178472798081893 ---- Accuracy = 0.5141416139240507\n",
      "Epoch = 24 ----- Step = 78 ----- Loss = 1.3006929370421398 ---- Accuracy = 0.5200751582278481\n",
      "Epoch = 25 ----- Step = 78 ----- Loss = 1.3033516950245145 ---- Accuracy = 0.5089992088607594\n",
      "Epoch = 26 ----- Step = 78 ----- Loss = 1.315223645560349 ---- Accuracy = 0.5084058544303798\n",
      "Epoch = 27 ----- Step = 78 ----- Loss = 1.2951772635496115 ---- Accuracy = 0.5174050632911392\n",
      "Epoch = 28 ----- Step = 78 ----- Loss = 1.2937262601490263 ---- Accuracy = 0.522745253164557\n",
      "Epoch = 29 ----- Step = 78 ----- Loss = 1.3074521233763876 ---- Accuracy = 0.5171083860759493\n",
      "Epoch = 30 ----- Step = 78 ----- Loss = 1.2805601433862615 ---- Accuracy = 0.5247231012658228\n",
      "Epoch = 31 ----- Step = 78 ----- Loss = 1.3001490869099581 ---- Accuracy = 0.5257120253164557\n",
      "Epoch = 32 ----- Step = 78 ----- Loss = 1.2962345744990096 ---- Accuracy = 0.5218552215189873\n",
      "Epoch = 33 ----- Step = 78 ----- Loss = 1.2965319307544563 ---- Accuracy = 0.5198773734177216\n",
      "Epoch = 34 ----- Step = 78 ----- Loss = 1.2743254371836215 ---- Accuracy = 0.5346123417721519\n",
      "Epoch = 35 ----- Step = 78 ----- Loss = 1.420288466200044 ---- Accuracy = 0.48595727848101267\n",
      "Epoch = 36 ----- Step = 78 ----- Loss = 1.311924640136429 ---- Accuracy = 0.512559335443038\n",
      "Epoch = 37 ----- Step = 78 ----- Loss = 1.271241999879668 ---- Accuracy = 0.5317444620253164\n",
      "Epoch = 38 ----- Step = 78 ----- Loss = 1.2738277791421624 ---- Accuracy = 0.5275909810126582\n",
      "Epoch = 39 ----- Step = 78 ----- Loss = 1.2961712939829766 ---- Accuracy = 0.5174050632911392\n",
      "Epoch = 40 ----- Step = 78 ----- Loss = 1.2559409609323815 ---- Accuracy = 0.5342167721518988\n",
      "Epoch = 41 ----- Step = 78 ----- Loss = 1.2872560009171692 ---- Accuracy = 0.5253164556962026\n",
      "Epoch = 42 ----- Step = 78 ----- Loss = 1.2971624241599553 ---- Accuracy = 0.5184928797468354\n",
      "Epoch = 43 ----- Step = 78 ----- Loss = 1.2639754693719405 ---- Accuracy = 0.5379746835443038\n",
      "Epoch = 44 ----- Step = 78 ----- Loss = 1.2790283583387543 ---- Accuracy = 0.5249208860759493\n",
      "Epoch = 45 ----- Step = 78 ----- Loss = 1.247429366353192 ---- Accuracy = 0.5339200949367089\n",
      "Epoch = 46 ----- Step = 78 ----- Loss = 1.2216331536256815 ---- Accuracy = 0.5538963607594937\n",
      "Epoch = 47 ----- Step = 78 ----- Loss = 1.2304342985153198 ---- Accuracy = 0.5410403481012658\n",
      "Epoch = 48 ----- Step = 78 ----- Loss = 1.213200858876675 ---- Accuracy = 0.5514240506329114\n",
      "Epoch = 49 ----- Step = 78 ----- Loss = 1.214459577693215 ---- Accuracy = 0.5552808544303798\n",
      "Epoch = 50 ----- Step = 78 ----- Loss = 1.231728672226773 ---- Accuracy = 0.5431170886075949\n",
      "Epoch = 51 ----- Step = 78 ----- Loss = 1.233579868002783 ---- Accuracy = 0.5481606012658228\n",
      "Epoch = 52 ----- Step = 78 ----- Loss = 1.1811968842639198 ---- Accuracy = 0.5664556962025317\n",
      "Epoch = 53 ----- Step = 78 ----- Loss = 1.2507077395161497 ---- Accuracy = 0.5464794303797469\n",
      "Epoch = 54 ----- Step = 78 ----- Loss = 1.2537306350997732 ---- Accuracy = 0.5396558544303798\n",
      "Epoch = 55 ----- Step = 78 ----- Loss = 1.2365056638476215 ---- Accuracy = 0.5495450949367089\n",
      "Epoch = 56 ----- Step = 78 ----- Loss = 1.4528125962124596 ---- Accuracy = 0.4710245253164557\n",
      "Epoch = 57 ----- Step = 78 ----- Loss = 1.3881361228001268 ---- Accuracy = 0.4846716772151899\n",
      "Epoch = 58 ----- Step = 78 ----- Loss = 1.2542539186115507 ---- Accuracy = 0.540743670886076\n",
      "Epoch = 59 ----- Step = 78 ----- Loss = 1.2360201787345018 ---- Accuracy = 0.5488528481012658\n",
      "Epoch = 60 ----- Step = 78 ----- Loss = 1.2166753939435453 ---- Accuracy = 0.5520174050632911\n",
      "Epoch = 61 ----- Step = 78 ----- Loss = 1.2102585661260388 ---- Accuracy = 0.5535996835443038\n",
      "Epoch = 62 ----- Step = 78 ----- Loss = 1.2121639885479891 ---- Accuracy = 0.5556764240506329\n",
      "Epoch = 63 ----- Step = 78 ----- Loss = 1.23717087431799 ---- Accuracy = 0.5495450949367089\n",
      "Epoch = 64 ----- Step = 78 ----- Loss = 1.216088042983526 ---- Accuracy = 0.5464794303797469\n",
      "Epoch = 65 ----- Step = 78 ----- Loss = 1.1998936662191078 ---- Accuracy = 0.5604232594936709\n",
      "Epoch = 66 ----- Step = 78 ----- Loss = 1.1656975006755395 ---- Accuracy = 0.571993670886076\n",
      "Epoch = 67 ----- Step = 78 ----- Loss = 1.179766673830491 ---- Accuracy = 0.5638844936708861\n",
      "Epoch = 68 ----- Step = 78 ----- Loss = 1.2373895056640045 ---- Accuracy = 0.5420292721518988\n",
      "Epoch = 69 ----- Step = 78 ----- Loss = 1.173719827132889 ---- Accuracy = 0.567939082278481\n",
      "Epoch = 70 ----- Step = 78 ----- Loss = 1.1848289445985722 ---- Accuracy = 0.5651700949367089\n",
      "Epoch = 71 ----- Step = 78 ----- Loss = 1.188079626499852 ---- Accuracy = 0.5639833860759493\n",
      "Epoch = 72 ----- Step = 78 ----- Loss = 1.1416337897505942 ---- Accuracy = 0.5782238924050633\n",
      "Epoch = 73 ----- Step = 78 ----- Loss = 1.2083501453641095 ---- Accuracy = 0.5603243670886076\n",
      "Epoch = 74 ----- Step = 78 ----- Loss = 1.1621285277076914 ---- Accuracy = 0.5741693037974683\n",
      "Epoch = 75 ----- Step = 78 ----- Loss = 1.1906957324547103 ---- Accuracy = 0.5637856012658228\n",
      "Epoch = 76 ----- Step = 78 ----- Loss = 1.234708711316314 ---- Accuracy = 0.5473694620253164\n",
      "Epoch = 77 ----- Step = 78 ----- Loss = 1.2576757669448853 ---- Accuracy = 0.552314082278481\n",
      "Epoch = 78 ----- Step = 78 ----- Loss = 1.225088677828825 ---- Accuracy = 0.5431170886075949\n",
      "Epoch = 79 ----- Step = 78 ----- Loss = 1.1846344455888 ---- Accuracy = 0.5671479430379747\n",
      "Epoch = 80 ----- Step = 78 ----- Loss = 1.155992861789993 ---- Accuracy = 0.5763449367088608\n",
      "Epoch = 81 ----- Step = 78 ----- Loss = 1.1523392494720748 ---- Accuracy = 0.5815862341772152\n",
      "Epoch = 82 ----- Step = 78 ----- Loss = 1.2233097779599926 ---- Accuracy = 0.5559731012658228\n",
      "Epoch = 83 ----- Step = 78 ----- Loss = 1.169230069540724 ---- Accuracy = 0.5709058544303798\n",
      "Epoch = 84 ----- Step = 78 ----- Loss = 1.139925215817705 ---- Accuracy = 0.5832674050632911\n",
      "Epoch = 85 ----- Step = 78 ----- Loss = 1.16159924374351 ---- Accuracy = 0.5727848101265823\n",
      "Epoch = 86 ----- Step = 78 ----- Loss = 1.1478400984896888 ---- Accuracy = 0.5850474683544303\n",
      "Epoch = 87 ----- Step = 78 ----- Loss = 1.1703535401368443 ---- Accuracy = 0.5703125\n",
      "Epoch = 88 ----- Step = 78 ----- Loss = 1.135942128640187 ---- Accuracy = 0.5815862341772152\n",
      "Epoch = 91 ----- Step = 78 ----- Loss = 1.1102257287954982 ---- Accuracy = 0.5989912974683544\n",
      "Epoch = 92 ----- Step = 78 ----- Loss = 1.1333454145660884 ---- Accuracy = 0.5863330696202531\n",
      "Epoch = 93 ----- Step = 78 ----- Loss = 1.1558072318004657 ---- Accuracy = 0.5800039556962026\n",
      "Epoch = 94 ----- Step = 78 ----- Loss = 1.1258332540717306 ---- Accuracy = 0.5862341772151899\n",
      "Epoch = 95 ----- Step = 78 ----- Loss = 1.1248911581461942 ---- Accuracy = 0.5881131329113924\n",
      "Epoch = 96 ----- Step = 78 ----- Loss = 1.148806164536295 ---- Accuracy = 0.5809928797468354\n",
      "Epoch = 97 ----- Step = 78 ----- Loss = 1.108823970903324 ---- Accuracy = 0.591376582278481\n",
      "Epoch = 98 ----- Step = 78 ----- Loss = 1.2757801587068582 ---- Accuracy = 0.542128164556962\n",
      "Epoch = 99 ----- Step = 78 ----- Loss = 1.1561066908172415 ---- Accuracy = 0.5789161392405063\n",
      "Epoch = 100 ----- Step = 78 ----- Loss = 1.1252829628654673 ---- Accuracy = 0.5926621835443038\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Train the VGG model\n",
    "epochs = 100\n",
    "vgg_model.train()\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    running_total = 0\n",
    "    for i, data in enumerate(train_dataloader_cifar10, 0):\n",
    "        total_len = len(train_dataloader_cifar10) -1\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer_vgg.zero_grad()\n",
    "\n",
    "        logits = vgg_model(inputs.cuda())\n",
    "        \n",
    "            \n",
    "        loss = criterion(logits, labels.cuda())\n",
    "        loss.backward()\n",
    "        #examine_grad(vgg_model)\n",
    "        optimizer_vgg.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_total +=1\n",
    "        accuracy+=calc_accuracy(logits,labels.cuda())\n",
    "        #if i % 10 == 0 or i == total_len :  # print every 2000 mini-batches\n",
    "        if i == total_len :\n",
    "            print(f\"Epoch = {epoch+1} ----- Step = {i} ----- Loss = {running_loss/running_total} ---- Accuracy = {accuracy/running_total}\")\n",
    "            running_loss = 0.0\n",
    "            accuracy = 0.0\n",
    "            running_total = 0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fdc4eb64-f0b3-4d89-8fb7-66defda3e8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the MLP network on the 10000 test images: 45 %\n"
     ]
    }
   ],
   "source": [
    "evaluate(vgg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d82e250-0b26-41b2-960d-5940886b3e98",
   "metadata": {},
   "source": [
    "It seems that freezing the initial layers on VGG and transfer learning on the lower layers doesnt have much effect. However Full fine tuning yields comparable results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c018c22-b4ee-4d29-b5f9-7e748314a66e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lrw",
   "language": "python",
   "name": "lrw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
